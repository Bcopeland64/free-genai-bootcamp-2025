[
  {
    "id": "arrays",
    "name": "Arrays",
    "description": "Arrays are a fundamental data structure that store elements of the same type in contiguous memory locations. They provide constant-time access to elements using indices, making them efficient for random access operations. However, arrays have a fixed size in many languages (though Python lists are dynamic), and operations like insertion and deletion can be expensive as they may require shifting elements.",
    "category": "dsa",
    "subcategory": null,
    "level": "beginner",
    "order_num": 1,
    "time_complexity": {
      "access": "O(1)",
      "search": "O(n)",
      "insertion": "O(n)",
      "deletion": "O(n)"
    },
    "space_complexity": "O(n)",
    "use_cases": [
      "Storage of homogeneous data",
      "Implementation of other data structures (stacks, queues, etc.)",
      "Matrix and grid representations",
      "Buffering and caching"
    ],
    "implementation_notes": "In Python, arrays are typically implemented using lists, which are dynamic arrays that can grow and shrink as needed."
  },
  {
    "id": "linked_lists",
    "name": "Linked Lists",
    "description": "Linked lists are linear data structures where elements are stored in nodes, and each node points to the next node in the sequence. Unlike arrays, linked lists don't require contiguous memory allocation and can grow or shrink dynamically. They come in various forms: singly-linked (nodes have a reference to the next node), doubly-linked (nodes have references to both next and previous nodes), and circular (the last node points back to the first).",
    "category": "dsa",
    "subcategory": null,
    "level": "beginner",
    "order_num": 2,
    "time_complexity": {
      "access": "O(n)",
      "search": "O(n)",
      "insertion": "O(1) (at beginning or with a reference to the position)",
      "deletion": "O(1) (with a reference to the node)"
    },
    "space_complexity": "O(n)",
    "use_cases": [
      "Implementation of stacks and queues",
      "Dynamic memory allocation",
      "Representation of sparse matrices",
      "Implementation of adjacency lists for graphs"
    ],
    "implementation_notes": "In Python, linked lists are typically implemented using custom classes with `next` (and sometimes `prev`) attributes pointing to other nodes."
  },
  {
    "id": "stacks",
    "name": "Stacks",
    "description": "A stack is a linear data structure that follows the Last-In-First-Out (LIFO) principle. Elements are added and removed from the same end, called the 'top' of the stack. The two primary operations are 'push' (add an element) and 'pop' (remove the most recently added element).",
    "category": "dsa",
    "subcategory": null,
    "level": "beginner",
    "order_num": 3,
    "time_complexity": {
      "push": "O(1)",
      "pop": "O(1)",
      "peek": "O(1)",
      "search": "O(n)"
    },
    "space_complexity": "O(n)",
    "use_cases": [
      "Function call management (call stack)",
      "Expression evaluation and conversion",
      "Undo mechanisms in applications",
      "Backtracking algorithms",
      "Balanced parentheses checking"
    ],
    "implementation_notes": "In Python, stacks can be implemented using lists with append() and pop() methods, or collections.deque for better performance."
  },
  {
    "id": "queues",
    "name": "Queues",
    "description": "A queue is a linear data structure that follows the First-In-First-Out (FIFO) principle. Elements are added at the 'rear' and removed from the 'front'. The main operations are 'enqueue' (add an element) and 'dequeue' (remove the oldest element).",
    "category": "dsa",
    "subcategory": null,
    "level": "beginner",
    "order_num": 4,
    "time_complexity": {
      "enqueue": "O(1)",
      "dequeue": "O(1)",
      "peek": "O(1)",
      "search": "O(n)"
    },
    "space_complexity": "O(n)",
    "use_cases": [
      "Task scheduling",
      "Resource allocation",
      "Breadth-first search in graphs",
      "Print job management",
      "Message buffers"
    ],
    "implementation_notes": "In Python, queues can be implemented using collections.deque for efficient operations at both ends, or the queue module for thread-safe implementations."
  },
  {
    "id": "hash_tables",
    "name": "Hash Tables",
    "description": "Hash tables are data structures that implement an associative array, mapping keys to values. They use a hash function to compute an index into an array of buckets, from which the desired value can be found. Hash tables provide fast lookups, insertions, and deletions.",
    "category": "dsa",
    "subcategory": null,
    "level": "intermediate",
    "order_num": 5,
    "time_complexity": {
      "search": "O(1) average, O(n) worst case",
      "insertion": "O(1) average, O(n) worst case",
      "deletion": "O(1) average, O(n) worst case"
    },
    "space_complexity": "O(n)",
    "use_cases": [
      "Database indexing",
      "Caching",
      "Symbol tables in compilers",
      "Associative arrays",
      "Counting frequencies (e.g., in counting sort)"
    ],
    "implementation_notes": "In Python, hash tables are implemented as dictionaries. The built-in dict type provides an efficient implementation with dynamic resizing."
  },
  {
    "id": "trees",
    "name": "Trees",
    "description": "Trees are hierarchical data structures consisting of nodes connected by edges. Each node can have zero or more child nodes, with one designated as the root. Binary trees, where each node has at most two children, are especially common. Trees organize data in a hierarchical way and provide efficient operations for insertion, deletion, and lookup.",
    "category": "dsa",
    "subcategory": null,
    "level": "intermediate",
    "order_num": 6,
    "time_complexity": {
      "search": "O(log n) for balanced trees, O(n) worst case",
      "insertion": "O(log n) for balanced trees, O(n) worst case",
      "deletion": "O(log n) for balanced trees, O(n) worst case"
    },
    "space_complexity": "O(n)",
    "use_cases": [
      "Hierarchical data representation (file systems, organization charts)",
      "Binary Search Trees for efficient searching",
      "Decision trees in machine learning",
      "Expression parsing",
      "Network routing algorithms"
    ],
    "implementation_notes": "In Python, trees are typically implemented using custom classes with references to child nodes."
  },
  {
    "id": "heaps",
    "name": "Heaps",
    "description": "Heaps are specialized tree-based data structures that satisfy the heap property: in a max heap, for any given node, the value of the node is greater than or equal to the values of its children; in a min heap, the value is less than or equal to the values of its children. Heaps are commonly implemented as arrays and are used in priority queue implementations.",
    "category": "dsa",
    "subcategory": null,
    "level": "intermediate",
    "order_num": 7,
    "time_complexity": {
      "find_min/max": "O(1)",
      "insert": "O(log n)",
      "delete_min/max": "O(log n)",
      "heapify": "O(n)"
    },
    "space_complexity": "O(n)",
    "use_cases": [
      "Priority queues",
      "Heap sort",
      "Graph algorithms (Dijkstra's, Prim's)",
      "Task scheduling",
      "Selection algorithms (finding kth smallest/largest element)"
    ],
    "implementation_notes": "In Python, heaps are implemented using the heapq module, which provides functions for working with min heaps."
  },
  {
    "id": "graphs",
    "name": "Graphs",
    "description": "Graphs are collections of nodes (vertices) connected by edges. They can be directed (edges have a direction) or undirected, and weighted (edges have values) or unweighted. Graphs represent relationships between objects and are used to model a wide variety of real-world problems.",
    "category": "dsa",
    "subcategory": null,
    "level": "advanced",
    "order_num": 8,
    "time_complexity": {
      "storage": "O(V+E) for adjacency list, O(V²) for adjacency matrix",
      "bfs/dfs": "O(V+E)",
      "shortest_path": "O(V²) for Dijkstra's with array, O(E log V) with heap"
    },
    "space_complexity": "O(V+E) for adjacency list, O(V²) for adjacency matrix",
    "use_cases": [
      "Social networks",
      "Transportation networks",
      "Web page connections",
      "Dependency analysis",
      "Circuit design"
    ],
    "implementation_notes": "In Python, graphs can be represented using adjacency lists (dictionaries of lists/sets), adjacency matrices (nested lists or NumPy arrays), or using dedicated libraries like NetworkX."
  },
  {
    "id": "sorting",
    "name": "Sorting Algorithms",
    "description": "Sorting algorithms arrange elements in a specific order (usually ascending or descending). Various algorithms exist with different time and space complexities, each with advantages in certain scenarios. Common algorithms include Bubble Sort, Insertion Sort, Selection Sort, Merge Sort, Quick Sort, and Heap Sort.",
    "category": "dsa",
    "subcategory": null,
    "level": "intermediate",
    "order_num": 9,
    "time_complexity": {
      "bubble_sort": "O(n²)",
      "insertion_sort": "O(n²)",
      "selection_sort": "O(n²)",
      "merge_sort": "O(n log n)",
      "quick_sort": "O(n log n) average, O(n²) worst",
      "heap_sort": "O(n log n)"
    },
    "space_complexity": {
      "bubble_sort": "O(1)",
      "insertion_sort": "O(1)",
      "selection_sort": "O(1)",
      "merge_sort": "O(n)",
      "quick_sort": "O(log n) average",
      "heap_sort": "O(1)"
    },
    "use_cases": [
      "Data preprocessing",
      "Database operations",
      "Information retrieval",
      "Statistical analysis",
      "User interfaces (displaying ordered lists)"
    ],
    "implementation_notes": "In Python, the built-in sorted() function and list.sort() method use Timsort, a hybrid of merge sort and insertion sort."
  },
  {
    "id": "searching",
    "name": "Searching Algorithms",
    "description": "Searching algorithms are used to find a specific element within a collection of data. Common algorithms include linear search, binary search (for sorted data), depth-first search and breadth-first search (for graphs and trees).",
    "category": "dsa",
    "subcategory": null,
    "level": "intermediate",
    "order_num": 10,
    "time_complexity": {
      "linear_search": "O(n)",
      "binary_search": "O(log n)",
      "dfs": "O(V+E) for graphs",
      "bfs": "O(V+E) for graphs"
    },
    "space_complexity": {
      "linear_search": "O(1)",
      "binary_search": "O(1) iterative, O(log n) recursive",
      "dfs": "O(h) where h is height of graph/tree",
      "bfs": "O(w) where w is maximum width of graph/tree"
    },
    "use_cases": [
      "Database queries",
      "Spell checkers",
      "Path finding in navigation",
      "Web search engines",
      "Finding elements in sorted arrays"
    ],
    "implementation_notes": "In Python, the 'in' operator performs searching in various data structures. For sorted lists, the bisect module provides binary search functionality."
  },
  {
    "id": "dynamic_programming",
    "name": "Dynamic Programming",
    "description": "Dynamic Programming (DP) is an algorithmic technique for solving complex problems by breaking them down into simpler subproblems. It solves each subproblem only once and stores the results to avoid redundant calculations, making it more efficient than recursive approaches for certain problems.",
    "category": "dsa",
    "subcategory": null,
    "level": "advanced",
    "order_num": 11,
    "time_complexity": "Varies by problem",
    "space_complexity": "Varies by problem",
    "use_cases": [
      "Fibonacci sequence computation",
      "Longest common subsequence",
      "Knapsack problem",
      "Shortest path algorithms",
      "Text justification"
    ],
    "implementation_notes": "In Python, DP is typically implemented using memoization (top-down approach with a cache) or tabulation (bottom-up approach with arrays/matrices)."
  },
  {
    "id": "greedy",
    "name": "Greedy Algorithms",
    "description": "Greedy algorithms make locally optimal choices at each step with the hope of finding a global optimum. They are simple and often intuitive but don't always yield the optimal solution for all problems. They work well when a problem has optimal substructure and the greedy choice property.",
    "category": "dsa",
    "subcategory": null,
    "level": "advanced",
    "order_num": 12,
    "time_complexity": "Varies by problem",
    "space_complexity": "Varies by problem",
    "use_cases": [
      "Huffman coding",
      "Prim's and Kruskal's algorithms for minimum spanning trees",
      "Dijkstra's algorithm for shortest paths",
      "Activity selection problems",
      "Coin change problem (with certain denomination systems)"
    ],
    "implementation_notes": "In Python, greedy algorithms are typically implemented by sorting or using priority queues (from the heapq module) to select the next best option at each step."
  }
]